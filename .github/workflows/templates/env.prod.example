# Production environment template for deployment.
# Copy to .env on the server (or .env.prod locally) and fill in real values.
# Do not commit secrets.

# Deployment image settings
COMPOSE_PROJECT_NAME=ai-coding-tutor
GHCR_REGISTRY=ghcr.io
GHCR_OWNER=your-github-username-or-org
GHCR_IMAGE_PREFIX=ai-coding-tutor
IMAGE_TAG=main

# Public domain and reverse proxy settings
SERVER_NAME=example.com
BACKEND_UPSTREAM=backend:8000
CLIENT_MAX_BODY_SIZE=16m
TLS_CERT_PATH=/etc/letsencrypt/live/example.com/fullchain.pem
TLS_KEY_PATH=/etc/letsencrypt/live/example.com/privkey.pem

# Database
POSTGRES_USER=postgres
POSTGRES_PASSWORD=change-this-strong-password
POSTGRES_DB=coding_tutor
DATABASE_URL=postgresql+asyncpg://postgres:change-this-strong-password@db:5432/coding_tutor
SQLALCHEMY_ECHO=false

# JWT and cookies
JWT_SECRET_KEY=replace-with-a-strong-random-string-at-least-32-chars
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7
AUTH_COOKIE_SECURE=true
AUTH_COOKIE_SAMESITE=lax

# Same-origin CORS for the public site
CORS_ORIGINS=["https://example.com"]

# Backend runtime
BACKEND_RELOAD=false

# LLM provider (default: Vertex AI Gemini via service account JSON)
LLM_PROVIDER=google
LLM_MODEL_GOOGLE=gemini-3-flash-preview
LLM_MODEL_ANTHROPIC=claude-sonnet-4-6
LLM_MODEL_OPENAI=gpt-5.2
ANTHROPIC_API_KEY=
OPENAI_API_KEY=
GOOGLE_API_KEY=
# Container path used by the backend (keep this stable).
GOOGLE_APPLICATION_CREDENTIALS=/run/secrets/google/service-account.json
# Absolute host path to the pre-placed Google service account JSON file.
# The Deploy Production workflow validates this file before running Docker Compose.
GOOGLE_APPLICATION_CREDENTIALS_HOST_PATH=/opt/ai-coding-tutor/secrets/ai-coding-tutor-service-account.json
GOOGLE_CLOUD_PROJECT_ID=ai-coding-tutor-488300
GOOGLE_VERTEX_GEMINI_LOCATION=global

# Embedding provider (default: Vertex multimodal embeddings using the same service account)
EMBEDDING_PROVIDER=vertex
EMBEDDING_MODEL_VERTEX=multimodalembedding@001
GOOGLE_VERTEX_EMBEDDING_LOCATION=us-central1
COHERE_API_KEY=
VOYAGEAI_API_KEY=

# Chat limits and cost controls
LLM_MAX_CONTEXT_TOKENS=10000
LLM_MAX_USER_INPUT_TOKENS=6000
CONTEXT_COMPRESSION_THRESHOLD=0.8
USER_WEEKLY_WEIGHTED_TOKEN_LIMIT=80000
CHAT_ENABLE_GREETING_FILTER=false
CHAT_ENABLE_OFF_TOPIC_FILTER=false
CHAT_SAME_PROBLEM_DETECTION_MODE=llm

# Rate limits
RATE_LIMIT_USER_PER_MINUTE=5
RATE_LIMIT_GLOBAL_PER_MINUTE=300
MAX_WS_CONNECTIONS_PER_USER=3

# Upload storage (persistent paths for production)
UPLOAD_STORAGE_DIR=/data/uploads
UPLOAD_EXPIRY_HOURS=24
UPLOAD_MAX_IMAGES_PER_MESSAGE=3
UPLOAD_MAX_DOCUMENTS_PER_MESSAGE=2
UPLOAD_MAX_IMAGE_MB=5
UPLOAD_MAX_DOCUMENT_MB=2
UPLOAD_MAX_DOCUMENT_TOKENS=6000

# Notebook storage (persistent paths for production)
NOTEBOOK_STORAGE_DIR=/data/notebooks
NOTEBOOK_MAX_SIZE_MB=5
NOTEBOOK_MAX_PER_USER=20
NOTEBOOK_MAX_CONTEXT_TOKENS=4000

# Admin accounts (comma, space, semicolon, or JSON array)
ADMIN_EMAIL=
# Preferred contact email for automatic Let's Encrypt issuance in the deploy workflow.
CERTBOT_EMAIL=
